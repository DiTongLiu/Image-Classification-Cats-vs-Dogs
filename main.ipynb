{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "955dc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73cb20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -O https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
    "# with zipfile.ZipFile('ImageLibrary.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall()\n",
    "# !pip install pydot\n",
    "# !pip install pydotplus\n",
    "# !pip install graphviz\n",
    "# !pip install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e79d3458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "807dd9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_skipped = 0\n",
    "for folder_name in (\"Cat\", \"Dog\"):\n",
    "    folder_path = os.path.join(\"PetImages\", folder_name)\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            fobj = open(fpath, \"rb\")\n",
    "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "        finally:\n",
    "            fobj.close()\n",
    "\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            # Delete corrupted image\n",
    "            os.remove(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "974a5f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23422 files belonging to 2 classes.\n",
      "Using 18738 files for training.\n",
      "Found 23422 files belonging to 2 classes.\n",
      "Using 4684 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (180, 180)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"PetImages\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"PetImages\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb9c6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea44f2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(buffer_size=32)\n",
    "val_ds = val_ds.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b4b94b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=image_size + (3,)\n",
    "num_classes=2\n",
    "\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "# Image augmentation block\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# Entry block\n",
    "x = layers.Rescaling(1.0 / 255)(x)\n",
    "x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "previous_block_activation = x  # Set aside residual\n",
    "\n",
    "for size in [128, 256, 512, 728]:\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "    # Project residual\n",
    "    residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "        previous_block_activation\n",
    "    )\n",
    "    x = layers.add([x, residual])  # Add back residual\n",
    "    previous_block_activation = x  # Set aside next residual\n",
    "    \n",
    "x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "if num_classes == 2:\n",
    "    activation = \"sigmoid\"\n",
    "    units = 1\n",
    "else:\n",
    "    activation = \"softmax\"\n",
    "    units = num_classes\n",
    "\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(units, activation=activation)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a15327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "# plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a654b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "586/586 [==============================] - 156s 262ms/step - loss: 0.6427 - accuracy: 0.6532 - val_loss: 0.9097 - val_accuracy: 0.5450\n",
      "Epoch 2/10\n",
      "586/586 [==============================] - 156s 266ms/step - loss: 0.4785 - accuracy: 0.7729 - val_loss: 0.6730 - val_accuracy: 0.6684\n",
      "Epoch 3/10\n",
      "586/586 [==============================] - 158s 270ms/step - loss: 0.3759 - accuracy: 0.8307 - val_loss: 0.3107 - val_accuracy: 0.8730\n",
      "Epoch 4/10\n",
      "586/586 [==============================] - 158s 270ms/step - loss: 0.2972 - accuracy: 0.8747 - val_loss: 0.5293 - val_accuracy: 0.8057\n",
      "Epoch 5/10\n",
      "586/586 [==============================] - 159s 271ms/step - loss: 0.2470 - accuracy: 0.8969 - val_loss: 0.2273 - val_accuracy: 0.9118\n",
      "Epoch 6/10\n",
      "586/586 [==============================] - 159s 272ms/step - loss: 0.2196 - accuracy: 0.9079 - val_loss: 0.2506 - val_accuracy: 0.9024\n",
      "Epoch 7/10\n",
      "586/586 [==============================] - 158s 270ms/step - loss: 0.1978 - accuracy: 0.9187 - val_loss: 0.2368 - val_accuracy: 0.9095\n",
      "Epoch 8/10\n",
      "586/586 [==============================] - 160s 273ms/step - loss: 0.1779 - accuracy: 0.9291 - val_loss: 0.2395 - val_accuracy: 0.8999\n",
      "Epoch 9/10\n",
      "586/586 [==============================] - 159s 272ms/step - loss: 0.1765 - accuracy: 0.9261 - val_loss: 0.3439 - val_accuracy: 0.8736\n",
      "Epoch 10/10\n",
      "586/586 [==============================] - 158s 270ms/step - loss: 0.1590 - accuracy: 0.9329 - val_loss: 0.1680 - val_accuracy: 0.9263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24423643d60>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3aa62e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>% cat</th>\n",
       "      <th>% dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cat/1</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>0.000198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat/2</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cat/3</td>\n",
       "      <td>0.828661</td>\n",
       "      <td>0.171339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cat/4</td>\n",
       "      <td>0.998566</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cat/5</td>\n",
       "      <td>0.877141</td>\n",
       "      <td>0.122859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dog/1</td>\n",
       "      <td>0.436351</td>\n",
       "      <td>0.563649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dog/2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dog/3</td>\n",
       "      <td>0.019226</td>\n",
       "      <td>0.980774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dog/4</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.999963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dog/5</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.99803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image     % cat     % dog\n",
       "0  Cat/1  0.999802  0.000198\n",
       "1  Cat/2  0.999985  0.000015\n",
       "2  Cat/3  0.828661  0.171339\n",
       "3  Cat/4  0.998566  0.001434\n",
       "4  Cat/5  0.877141  0.122859\n",
       "5  Dog/1  0.436351  0.563649\n",
       "6  Dog/2       N/A       N/A\n",
       "7  Dog/3  0.019226  0.980774\n",
       "8  Dog/4  0.000037  0.999963\n",
       "9  Dog/5   0.00197   0.99803"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "image_list = []\n",
    "cat_list = []\n",
    "dog_list = []\n",
    "\n",
    "for animal in ['Cat','Dog']:\n",
    "    for i in range(1,6):\n",
    "        try:\n",
    "            img = keras.preprocessing.image.load_img(\n",
    "                \"PetImages/\"+animal+\"/\"+str(i)+\".jpg\", target_size=image_size\n",
    "            )\n",
    "            img_array = keras.preprocessing.image.img_to_array(img)\n",
    "            img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "            predictions = model.predict(img_array)\n",
    "            score = predictions[0]\n",
    "            cat_list.append(1-score[0])\n",
    "            dog_list.append(score[0])\n",
    "            \n",
    "        except:\n",
    "            cat_list.append('N/A')\n",
    "            dog_list.append('N/A')\n",
    "            \n",
    "        image_list.append(animal+\"/\"+str(i))\n",
    "            \n",
    "df['image'] = image_list\n",
    "df['% cat'] = cat_list\n",
    "df['% dog'] = dog_list\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu] *",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
